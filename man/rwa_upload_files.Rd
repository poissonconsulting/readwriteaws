% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rwa-upload-files.R
\name{rwa_upload_files}
\alias{rwa_upload_files}
\title{Upload Files from a Local Drive to an AWS S3 Bucket}
\usage{
rwa_upload_files(
  file_list,
  directory = ".",
  bucket_name,
  bucket_path = "",
  aws_access_key_id = Sys.getenv("AWS_ACCESS_KEY_ID"),
  aws_secret_access_key = Sys.getenv("AWS_SECRET_ACCESS_KEY"),
  region = Sys.getenv("AWS_REGION", "ca-central-1")
)
}
\arguments{
\item{file_list}{A character vector of file(s).}

\item{directory}{A string (by default \code{"."}) indicating the directory where
the files are locally located.}

\item{bucket_name}{A string of the AWS S3 bucket name.}

\item{bucket_path}{A string (by default \code{""}) to prefix the file path in the
bucket. This allows you to place files in a different folder in the bucket
then locally. If the default is used the file structure will be identical
to the \code{file_list} passed.}

\item{aws_access_key_id}{A string of your AWS user access key ID. The default
is the environment variable named \code{AWS_ACCESS_KEY_ID}.}

\item{aws_secret_access_key}{A string of your AWS user secret access key. The
default is the environment variable named \code{AWS_SECRET_ACCESS_KEY}.}

\item{region}{A string of the AWS region. The default is the environment
variable named \code{AWS_REGION}.}
}
\description{
Upload files from your local drive to an AWS S3 bucket
}
\details{
The directory argument can take either relative or absolute file
paths. The \code{directory} and \code{file_list} argument are designed to be used
together but \code{file_list} can be used alone and pass \code{NULL} to \code{directory}.

The \code{bucket_path} argument makes it possible to place files in a different
folder path in the bucket then locally. The \code{bucket_path} argument is
appended to the \code{file_list}. The \code{directory} argument is not included in
the file path of the files in the bucket.
}
\examples{
\dontrun{
# Upload a single file to the Purple Lake project
rwa_upload_files(
  file_list = "shiny-upload/image/2021-06-30_16-06-10_test_04d855/input_data.csv",
  directory = "purple-lake",
  bucket_name = "purple-lake-poissonconsulting"
)

# Upload multiple files to the Purple Lake project
files <- c(
  "shiny-upload/image/2021-06-30_16-06-10_test_04d855/uploaded_file.jpeg",
  "shiny-upload/image/2021-06-30_16-06-10_test_04d855/input_data.csv"
)
rwa_upload_files(
  file_list = files,
  directory = "purple-lake",
  bucket_name = "purple-lake-poissonconsulting"
)

# Store file in different file path in AWS then locally stored
rwa_upload_files(
  file_list = "shiny-upload/image/2021-06-30_16-06-10_test_04d855/input_data.csv",
  directory = "purple-lake",
  bucket_name = "purple-lake-poissonconsulting",
  bucket_path = "extra_data"
)

# Enter AWS credentials directly into the function
rwa_upload_files(
  file_list = "shiny-upload/image/2021-06-30_16-06-10_test_04d855/input_data.csv",
  directory = "purple-lake",
  bucket_name = "purple-lake-poissonconsulting",
  aws_access_key_id = "AHSGYWKJDIUAHDSJ",
  aws_secret_access_key = "8HYGD54//hgdx^785809",
  region = "us-east-1"
)
}

}
